import gradio as gr
import random
import os
from llama_cpp import Llama
from pywhispercpp.model import Model

# å®šä¹‰æ¨¡å‹åç§°å’Œè·¯å¾„çš„æ˜ å°„
model_paths = {
    "Qwen2.5-3B-Instruct-Q4_0_4_4": "../../Qwen2.5-3B-Instruct-Q4_0_4_4.gguf",
    "Qwen2.5-7B-Instruct-Q4_0_4_4": "../../Qwen2.5-7B-Instruct-Q4_0_4_4.gguf",
}
# åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¤„ç†æ¨¡å‹é€‰æ‹©ï¼Œå¹¶è¿”å›æ¨¡å‹è·¯å¾„
def get_model_path(selected_model_name):
    return model_paths[selected_model_name]

model_path = "../../Qwen2.5-3B-Instruct-Q4_0_4_4.gguf"  # é»˜è®¤llmæ¨¡å‹è·¯å¾„

#  ä½¿ç”¨ whisper.cpp
# å…¨å±€å˜é‡
whisper_model = None

def load_model():
    global whisper_model
    if whisper_model is None:
        whisper_model = Model('../../ggml-small-q4_0.bin')
# audio to text here
def audio_to_text(audio_path):
    """
    audio to text hereï¼Œç›®å‰æ˜¯ whisper.cpp
    Parameters:
    audio_path: str, éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    Returns:
    transcription.text: str, éŸ³é¢‘è½¬æ¢çš„æ–‡æœ¬
    """
    load_model()  # ç¡®ä¿æ¨¡å‹åªåŠ è½½ä¸€æ¬¡
    if not audio_path:
        return None
    print(f"æ­£åœ¨å¤„ç†audio_path:{audio_path}")
    params = {
        'n_threads': 8,
        'language': 'auto',  
        'initial_prompt': 'ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„å¥å­',
    }
    result = whisper_model.transcribe(audio_path, **params)
    text = ''.join(segment.text for segment in result)
    print("Transcription text:", text)
    return text



# Assuming you are in the Kokoro-82M directory
from onnxruntime import InferenceSession
import torch
import numpy as np
from scipy.io.wavfile import write
import phonemizer
import re


def split_num(num):
    num = num.group()
    if "." in num:
        return num
    elif ":" in num:
        h, m = [int(n) for n in num.split(":")]
        if m == 0:
            return f"{h} o'clock"
        elif m < 10:
            return f"{h} oh {m}"
        return f"{h} {m}"
    year = int(num[:4])
    if year < 1100 or year % 1000 < 10:
        return num
    left, right = num[:2], int(num[2:4])
    s = "s" if num.endswith("s") else ""
    if 100 <= year % 1000 <= 999:
        if right == 0:
            return f"{left} hundred{s}"
        elif right < 10:
            return f"{left} oh {right}{s}"
    return f"{left} {right}{s}"


def flip_money(m):
    m = m.group()
    bill = "dollar" if m[0] == "$" else "pound"
    if m[-1].isalpha():
        return f"{m[1:]} {bill}s"
    elif "." not in m:
        s = "" if m[1:] == "1" else "s"
        return f"{m[1:]} {bill}{s}"
    b, c = m[1:].split(".")
    s = "" if b == "1" else "s"
    c = int(c.ljust(2, "0"))
    coins = (
        f"cent{'' if c == 1 else 's'}"
        if m[0] == "$"
        else ("penny" if c == 1 else "pence")
    )
    return f"{b} {bill}{s} and {c} {coins}"


def point_num(num):
    a, b = num.group().split(".")
    return " point ".join([a, " ".join(b)])


def normalize_text(text):
    text = text.replace(chr(8216), "'").replace(chr(8217), "'")
    text = text.replace("Â«", chr(8220)).replace("Â»", chr(8221))
    text = text.replace(chr(8220), '"').replace(chr(8221), '"')
    text = text.replace("(", "Â«").replace(")", "Â»")
    for a, b in zip("ã€ã€‚ï¼ï¼Œï¼šï¼›ï¼Ÿ", ",.!,:;?"):
        text = text.replace(a, b + " ")
    text = re.sub(r"[^\S \n]", " ", text)
    text = re.sub(r"  +", " ", text)
    text = re.sub(r"(?<=\n) +(?=\n)", "", text)
    text = re.sub(r"\bD[Rr]\.(?= [A-Z])", "Doctor", text)
    text = re.sub(r"\b(?:Mr\.|MR\.(?= [A-Z]))", "Mister", text)
    text = re.sub(r"\b(?:Ms\.|MS\.(?= [A-Z]))", "Miss", text)
    text = re.sub(r"\b(?:Mrs\.|MRS\.(?= [A-Z]))", "Mrs", text)
    text = re.sub(r"\betc\.(?! [A-Z])", "etc", text)
    text = re.sub(r"(?i)\b(y)eah?\b", r"\1e'a", text)
    text = re.sub(
        r"\d*\.\d+|\b\d{4}s?\b|(?<!:)\b(?:[1-9]|1[0-2]):[0-5]\d\b(?!:)", split_num, text
    )
    text = re.sub(r"(?<=\d),(?=\d)", "", text)
    text = re.sub(
        r"(?i)[$Â£]\d+(?:\.\d+)?(?: hundred| thousand| (?:[bm]|tr)illion)*\b|[$Â£]\d+\.\d\d?\b",
        flip_money,
        text,
    )
    text = re.sub(r"\d*\.\d+", point_num, text)
    text = re.sub(r"(?<=\d)-(?=\d)", " to ", text)
    text = re.sub(r"(?<=\d)S", " S", text)
    text = re.sub(r"(?<=[BCDFGHJ-NP-TV-Z])'?s\b", "'S", text)
    text = re.sub(r"(?<=X')S\b", "s", text)
    text = re.sub(
        r"(?:[A-Za-z]\.){2,} [a-z]", lambda m: m.group().replace(".", "-"), text
    )
    text = re.sub(r"(?i)(?<=[A-Z])\.(?=[A-Z])", "-", text)
    return text.strip()


phonemizers = dict(
    a=phonemizer.backend.EspeakBackend(
        language="en-us", preserve_punctuation=True, with_stress=True
    ),
    b=phonemizer.backend.EspeakBackend(
        language="en-gb", preserve_punctuation=True, with_stress=True
    ),
)


def phonemize(text, lang, norm=True):
    if norm:
        text = normalize_text(text)
    ps = phonemizers[lang].phonemize([text])
    ps = ps[0] if ps else ""
    # https://en.wiktionary.org/wiki/kokoro#English
    ps = ps.replace("kÉ™kËˆoËÉ¹oÊŠ", "kËˆoÊŠkÉ™É¹oÊŠ").replace("kÉ™kËˆÉ”ËÉ¹É™ÊŠ", "kËˆÉ™ÊŠkÉ™É¹É™ÊŠ")
    ps = ps.replace("Ê²", "j").replace("r", "É¹").replace("x", "k").replace("É¬", "l")
    ps = re.sub(r"(?<=[a-zÉ¹Ë])(?=hËˆÊŒndÉ¹Éªd)", " ", ps)
    ps = re.sub(r' z(?=[;:,.!?Â¡Â¿â€”â€¦"Â«Â»â€œâ€ ]|$)', "z", ps)
    if lang == "a":
        ps = re.sub(r"(?<=nËˆaÉªn)ti(?!Ë)", "di", ps)
    ps = "".join(filter(lambda p: p in VOCAB, ps))
    return ps.strip()


def get_vocab():
    _pad = "$"
    _punctuation = ';:,.!?Â¡Â¿â€”â€¦"Â«Â»â€œâ€ '
    _letters = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
    _letters_ipa = "É‘ÉÉ’Ã¦É“Ê™Î²É”É•Ã§É—É–Ã°Ê¤É™É˜ÉšÉ›ÉœÉÉÉŸÊ„É¡É É¢Ê›É¦É§Ä§É¥ÊœÉ¨ÉªÊÉ­É¬É«É®ÊŸÉ±É¯É°Å‹É³É²É´Ã¸ÉµÉ¸Î¸Å“É¶Ê˜É¹ÉºÉ¾É»Ê€ÊÉ½Ê‚ÊƒÊˆÊ§Ê‰ÊŠÊ‹â±±ÊŒÉ£É¤ÊÏ‡ÊÊÊ‘ÊÊ’Ê”Ê¡Ê•Ê¢Ç€ÇÇ‚ÇƒËˆËŒËË‘Ê¼Ê´Ê°Ê±Ê²Ê·Ë Ë¤Ëâ†“â†‘â†’â†—â†˜'Ì©'áµ»"
    symbols = [_pad] + list(_punctuation) + list(_letters) + list(_letters_ipa)
    dicts = {}
    for i in range(len((symbols))):
        dicts[symbols[i]] = i
    return dicts


VOCAB = get_vocab()


def tokenize(ps):
    return [i for i in map(VOCAB.get, ps) if i is not None]


def generate(text, voicepack, lang="a", speed=1, ps=None):
    ps = ps or phonemize(text, lang)
    tokens = tokenize(ps)
    return tokens


# Tokens produced by phonemize() and tokenize() in kokoro.py
# tokens = [50, 157, 43, 135, 16, 53, 135, 46, 16, 43, 102, 16, 56, 156, 57, 135, 6, 16, 102, 62, 61, 16, 70, 56, 16, 138, 56, 156, 72, 56, 61, 85, 123, 83, 44, 83, 54, 16, 53, 65, 156, 86, 61, 62, 131, 83, 56, 4, 16, 54, 156, 43, 102, 53, 16, 156, 72, 61, 53, 102, 112, 16, 70, 56, 16, 138, 56, 44, 156, 76, 158, 123, 56, 16, 62, 131, 156, 43, 102, 54, 46, 16, 102, 48, 16, 81, 47, 102, 54, 16, 54, 156, 51, 158, 46, 16, 70, 16, 92, 156, 135, 46, 16, 54, 156, 43, 102, 48, 4, 16, 81, 47, 102, 16, 50, 156, 72, 64, 83, 56, 62, 16, 156, 51, 158, 64, 83, 56, 16, 44, 157, 102, 56, 16, 44, 156, 76, 158, 123, 56, 4]

VOICE_NAME = [
    "af",  # Default voice is a 50-50 mix of Bella & Sarah
    "af_bella",
    "af_sarah",
    "am_adam",
    "am_michael",
    "bf_emma",
    "bf_isabella",
    "bm_george",
    "bm_lewis",
    "af_nicole",
    "af_sky",
][0]
VOICEPACK = torch.load(f"voices/{VOICE_NAME}.pt", weights_only=True)
print(f"Loaded voice: {VOICE_NAME}")

def process_tts(text, output_dir="output"):
    """
    å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜ä¸ºéŸ³é¢‘æ–‡ä»¶ã€‚

    å‚æ•°:
        text (str): å¾…è½¬æ¢çš„æ–‡æœ¬ã€‚
        output_dir (str): ä¿å­˜éŸ³é¢‘æ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸º "output"ã€‚

    è¿”å›:
        path (str): ä¿å­˜éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_dir, exist_ok=True)

    tokens = generate(text, VOICEPACK)

    # Context length is 512, but leave room for the pad token 0 at the start & end
    assert len(tokens) <= 510, len(tokens)

    # Style vector based on len(tokens), ref_s has shape (1, 256)
    ref_s = torch.load("voices/af.pt")[len(tokens)].numpy()

    # Add the pad ids, and reshape tokens, should now have shape (1, <=512)
    tokens = [[0, *tokens, 0]]

    sess = InferenceSession("kokoro-v0_19.onnx")

    audio = sess.run(
        None, dict(tokens=tokens, style=ref_s, speed=np.ones(1, dtype=np.float32))
    )[0]

    # 3ï¸âƒ£ ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    output_path = os.path.join(output_dir, "output_audio.wav")
    write(output_path, 24000, audio)  # é‡‡æ ·ç‡ä¸º 24000 Hz

    print(f"Audio saved to {output_path}")
    return output_path

def get_audio(gr_states, audio):
    """
    åœ¨gradioä¸Šæ¸²æŸ“audioç»„ä»¶, æ›´æ–°chatbotç»„ä»¶
    """
    if not gr_states["history"]:
        return audio
    
    response = gr_states["history"][-1][1] if len(gr_states["history"][-1]) > 1 else None
    # print(gr_states)
    if response == "Connection Error: è¯·æ±‚å¤±è´¥ï¼Œè¯·é‡è¯•" or response is None:
        gr_states["history"].pop()
        return audio
    else:
        audio = process_tts(response)
        return audio


class LLMResponse:
    def __init__(self, model_path):
        self.llm = Llama(
            model_path=model_path,
            chat_format="chatml",
            n_ctx=1024,
            n_threads=8,
        )

    def get_response(self, messages):
        # åˆ›å»ºèŠå¤©å®Œæˆ
        response = self.llm.create_chat_completion(
            messages=messages,
            stream=True,
            max_tokens=512,
            top_p=0.8,  # é‡‡æ ·æ¦‚ç‡é˜ˆå€¼
            top_k=100,  # é‡‡æ ·æ•°é‡
            temperature=0.7,  # æ¸©åº¦
        )
        # æµå¼è¿”å›AIçš„å“åº”
        for chunk in response:
            if "choices" in chunk and chunk["choices"]:
                delta = chunk["choices"][0].get("delta", {})
                content = delta.get("content", "")
                if content:
                    yield content

def chat_completions(messages, gr_states, history, selected_model_name):
    """
    Chat completion here, using llama-cpp-python now.
    Parameters:
    messages: openai format messages
    gr_states: dict, global states
    history: list, conversation history
    Returns:
    gr_states: dict, updated global states
    history: list, updated conversation history
    """
    if not messages:
        return gr_states, history
    
    # Initialize the LLM model
    model_path = get_model_path(selected_model_name)  # æ ¹æ®æ¨¡å‹åç§°è·å–è·¯å¾„
    llm_response = LLMResponse(model_path)
    
    # æ„å»ºåŒ…å«æ•´ä¸ªå¯¹è¯å†å²çš„æ¶ˆæ¯åˆ—è¡¨
    full_messages = [
        {"role": "system", "content": gr_states["system_prompt"]},
    ]
    # æ·»åŠ å†å²å¯¹è¯åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
    for usr, bot in history:
        full_messages.append({"role": "user", "content": usr})
        if bot:
            full_messages.append({"role": "assistant", "content": bot})
    
    # æ·»åŠ æœ€æ–°çš„ç”¨æˆ·è¾“å…¥
    full_messages.append({"role": "user", "content": messages[-1]['content']})
    
    # Get the response from the LLM model
    ai_response = ""
    for content in llm_response.get_response(full_messages):
        ai_response += content
        gr_states["history"][-1][1] = ai_response  # æ›´æ–°å†å²è®°å½•
        history[-1][1] = ai_response  # æ›´æ–° history
        yield gr_states, history  # é€æ­¥è¿”å›æ›´æ–°åçš„ gr_states å’Œ history
    
    # Update the conversation history
    user_input = messages[-1]['content']
    if user_input:
        if not gr_states["history"]:
            gr_states["history"] = []
        gr_states["history"].append([user_input, ai_response])
        history.pop()
        history.append(gr_states["history"][-1])
    
    yield gr_states, history



def init_default_role():
    """
    åˆå§‹åŒ–é»˜è®¤è§’è‰²
    æ ¹æ®è§’è‰²ç¡®å®š system prompt
    """
    system_prompt = "ä½ æ˜¯ä¸€åªä¼šè¯´è¯çš„é’è›™ï¼Œä½†æ— è®ºè¯´ä»€ä¹ˆéƒ½çˆ±åœ¨æœ€ååŠ ä¸Š'å‘±å”§å‘±å”§'ã€‚"
    role = "ä¸€åªç”¨äºæ¼”ç¤ºçš„é’è›™ ğŸ¸"
    role_description = "æˆ‘æ˜¯ä¸€åªä¼šè¯´è¯çš„é’è›™ğŸ¸ï¼Œä½†æ— è®ºè¯´ä»€ä¹ˆéƒ½çˆ±åœ¨æœ€ååŠ ä¸Š'å‘±å”§å‘±å”§'ã€‚"
    return role, role_description, system_prompt

def get_random_role():
    """
    éšæœºè·å–ä¸€ä¸ªè§’è‰²ï¼Œè¿™é‡Œåªæ˜¯ä¸€ä¸ªç¤ºä¾‹å‡½æ•°
    æ ¹æ®è§’è‰²ç¡®å®š system prompt
    """
    roles = [
        {
            "name": "0å·å°é’è›™ ğŸ¸",
            "description": "æˆ‘æ˜¯ä¸€åªä¼šè¯´è¯çš„é’è›™ğŸ¸ï¼Œä½†æ— è®ºè¯´ä»€ä¹ˆéƒ½çˆ±åœ¨æœ€ååŠ ä¸Š'å‘±å”§å‘±å”§'ã€‚",
            "system_prompt": "ä½ æ˜¯ä¸€åªä¼šè¯´è¯çš„é’è›™ï¼Œä½†æ— è®ºè¯´ä»€ä¹ˆéƒ½çˆ±åœ¨æœ€ååŠ ä¸Š'å‘±å”§å‘±å”§'ã€‚"
        },
        {
            "name": "1å·å°è€è™ ğŸ¯",
            "description": "æˆ‘æ˜¯ä¸€åªå‹‡æ•¢çš„å°è€è™ğŸ¯ï¼Œè¯´è¯æ—¶æ€»æ˜¯å……æ»¡åŠ›é‡ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å—·å‘œå—·å‘œ'ã€‚",
            "system_prompt": "ä½ æ˜¯ä¸€åªå‹‡æ•¢çš„å°è€è™ï¼Œè¯´è¯æ—¶æ€»æ˜¯å……æ»¡åŠ›é‡ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å—·å‘œå—·å‘œ'ã€‚"
        },
        {
            "name": "2å·å°çŒ«å’ª ğŸ±",
            "description": "æˆ‘æ˜¯ä¸€åªæ¸©æŸ”çš„å°çŒ«å’ªğŸ±ï¼Œè¯´è¯æ—¶å£°éŸ³æŸ”å’Œï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å–µå–µå–µå–µ'ã€‚",
            "system_prompt": "ä½ æ˜¯ä¸€åªæ¸©æŸ”çš„å°çŒ«å’ªï¼Œè¯´è¯æ—¶å£°éŸ³æŸ”å’Œï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å–µå–µå–µå–µ'ã€‚"
        },
        {
            "name": "3å·å°æ°´ç‰› ğŸ®",
            "description": "æˆ‘æ˜¯ä¸€åªå‹¤åŠ³çš„å°æ°´ç‰›ğŸ®ï¼Œè¯´è¯æ—¶æ€»æ˜¯æ…¢æ¡æ–¯ç†ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å“å“å“å“'ã€‚",
            "system_prompt": "ä½ æ˜¯ä¸€åªå‹¤åŠ³çš„å°æ°´ç‰›ï¼Œè¯´è¯æ—¶æ€»æ˜¯æ…¢æ¡æ–¯ç†ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å“å“å“å“'ã€‚"
        },
        {
            "name": "4å·å°ç‹—ç‹— ğŸ¶",
            "description": "æˆ‘æ˜¯ä¸€åªå¿ è¯šçš„å°ç‹—ç‹—ğŸ¶ï¼Œè¯´è¯æ—¶æ€»æ˜¯çƒ­æƒ…æ´‹æº¢ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'æ±ªå‘œæ±ªå‘œ'ã€‚",
            "system_prompt": "ä½ æ˜¯ä¸€åªå¿ è¯šçš„å°ç‹—ç‹—ï¼Œè¯´è¯æ—¶æ€»æ˜¯çƒ­æƒ…æ´‹æº¢ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'æ±ªå‘œæ±ªå‘œ'ã€‚"
        },
        {
            "name": "5å·å°å–œé¹Š ğŸ¦",
            "description": "æˆ‘æ˜¯ä¸€åªå¿«ä¹çš„å°å–œé¹ŠğŸ¦ï¼Œè¯´è¯æ—¶æ€»æ˜¯å¸¦ç€å¥½æ¶ˆæ¯ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å–³å–³å”§å”§'ã€‚",
            "system_prompt": "ä½ æ˜¯ä¸€åªå¿«ä¹çš„å°å–œé¹Šï¼Œè¯´è¯æ—¶æ€»æ˜¯å¸¦ç€å¥½æ¶ˆæ¯ï¼Œå–œæ¬¢åœ¨å¥å­æœ«å°¾åŠ ä¸Š'å–³å–³å”§å”§'ã€‚"
        }
    ]
    
    i = random.randint(0, len(roles) - 1)
    selected_role = roles[i]
    
    role = selected_role["name"]
    role_description = selected_role["description"]
    system_prompt = selected_role["system_prompt"]
    
    return role, role_description, system_prompt



def format_messages(user_message, gr_states, history):
    """prepare the request data [messages] for the chatbot
    Parameters:
    user_message: str, ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
    gr_states: dict, {"system_prompt": str, "history": List, "user_prompt": str}
    history: list, èŠå¤©è®°å½•ï¼Œä¸€ä¸ªåµŒå¥—åˆ—è¡¨: [["ç”¨æˆ·æ¶ˆæ¯", "botå›å¤"],["ç”¨æˆ·æ¶ˆæ¯", "botå›å¤"]]
    """
    messages = [
        {
            "role": "system",
            "content": gr_states["system_prompt"],
        },
    ]
    history.append([user_message, None])
    if len(user_message) > 0:
        if not gr_states["history"]:
            gr_states["history"] = []
        gr_states["history"].append([user_message, None])
    for [usr, bot] in history:
        messages.append({
            "role": "user",
            "content": usr
        })
        if bot:
            messages.append({
                "role": "assistant",
                "content": bot
            })
    return messages, gr_states, history

def set_up(gr_states):
    """
    maybe éšæœºåˆ‡æ¢ä¸€ä¸ªè§’è‰²
    """
    role_name, role_description, system_prompt = get_random_role()
    gr_states = {"system_prompt": system_prompt, "history": []}
    role_info_display = f''' # {role_name}
    {role_description}
    '''
    history = []
    return history, gr_states, role_info_display, None


theme = gr.themes.Soft(
    font=['ui-sans-serif'],
    font_mono=['ui-monospace'],
)

with gr.Blocks(theme=theme) as demo:
    demo.title = 'Audio Chat ğŸ™ï¸'
    gr.Markdown('''<center><strong style="font-size: 24px;">âœ¨ Audio Chat ğŸ™ï¸</strong></center>''')
    
    role_name, role_description, system_prompt = init_default_role()
    gr_states = gr.State({"system_prompt": system_prompt, "history": []})
    messages = gr.State(None)
    # with gr.Tab(label='demo'):
    with gr.Row():
        role_info_display = gr.Markdown(f''' # {role_name}
        {role_description}
        ''')
    with gr.Row():
        with gr.Column(scale=7):
            with gr.Row():
                chatbot = gr.Chatbot(label='èŠå¤©ç•Œé¢', value=[], height=600, visible=True)
            with gr.Row():
                with gr.Column(scale=2):
                    user_prompt = gr.Textbox(label='å¯¹è¯è¾“å…¥æ¡†ï¼ˆæŒ‰Enterå‘é€æ¶ˆæ¯ï¼‰', interactive=True, visible=True)
                    user_prompt_state = gr.State("")  # åˆ›å»ºä¸€ä¸ªçŠ¶æ€å˜é‡æ¥å­˜å‚¨è¾“å…¥æ¡†çš„å†…å®¹
                with gr.Column(scale=1):
                    with gr.Row():
                        send_btn = gr.Button("Send Message")
                    with gr.Row():
                        clear_btn = gr.Button("Clear Message")

        with gr.Column(scale=3):
            with gr.Row():
                change_btn = gr.Button("éšæœºæ¢ä¸€ä¸ªè§’è‰²")
            with gr.Row():
                default_role_btn = gr.Button("åˆ‡æ¢å›é»˜è®¤è§’è‰²")
            with gr.Row():
                model = gr.Dropdown(
                                label="Choose Model:",
                                choices=list(model_paths.keys()),  # åªæ˜¾ç¤ºæ¨¡å‹çš„åç§°
                                value=list(model_paths.keys())[0] if model_paths else None,  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªæ¨¡å‹
                                interactive=True,
                                allow_custom_value=True,
                            )
            with gr.Row():
                input_audio = gr.Audio(label="è¯­éŸ³è¾“å…¥æ¡†", type="filepath")
            with gr.Row():
                examples_list = [
                    [
                        "./audio_test/1.mp3",
                    ],
                    [
                        "./audio_test/2.mp3",
                    ],
                    [
                        "./audio_test/3.mp3",
                    ],
                    [
                        "./audio_test/4.mp3",
                    ],
                ]
                gr.Examples(examples=examples_list, inputs=[input_audio])
            with gr.Row():
                audio = gr.Audio(label="output", interactive=False)



    # å®šä¹‰clear messageæŒ‰é’®çš„å›è°ƒå‡½æ•°
    def clear_message(user_prompt):
        """
        æ¸…ç©ºè¾“å…¥æ¡†çš„å›è°ƒå‡½æ•°
        """
        return ""

    # å°†send messageæŒ‰é’®ä¸å›è°ƒå‡½æ•°å…³è”
    send_btn.click(
        format_messages,  # ç¬¬ä¸€æ­¥ï¼šæ ¼å¼åŒ–æ¶ˆæ¯
        inputs=[user_prompt, gr_states, chatbot],
        outputs=[messages, gr_states, chatbot]
    ).then(
        chat_completions,  # ç¬¬äºŒæ­¥ï¼šå¤„ç†èŠå¤©å®Œæˆ
        inputs=[messages, gr_states, chatbot, model],
        outputs=[gr_states, chatbot]
    ).then(
        get_audio,  # ç¬¬ä¸‰æ­¥ï¼šå¤„ç†éŸ³é¢‘è¾“å‡º
        inputs=[gr_states, audio],
        outputs=[audio]
    ).then(
        clear_message, 
        inputs=[user_prompt], 
        outputs=[user_prompt]
    )

    # å°†clear messageæŒ‰é’®ä¸å›è°ƒå‡½æ•°å…³è”
    clear_btn.click(
        clear_message, 
        inputs=[user_prompt], 
        outputs=[user_prompt]
    )
    
    user_prompt.submit(
        format_messages, [user_prompt, gr_states, chatbot], [messages, gr_states, chatbot]).then(
        chat_completions, [messages, gr_states, chatbot, model], [gr_states, chatbot]).then(
        get_audio, [gr_states, audio], audio
    ).then(
        clear_message, 
        inputs=[user_prompt], 
        outputs=[user_prompt]
    )
    input_audio.change(audio_to_text, input_audio, user_prompt)
    change_btn.click(set_up, gr_states, [chatbot, gr_states, role_info_display, audio])

    def reset_to_default_role(gr_states):
        """
        é‡ç½®ä¸ºé»˜è®¤è§’è‰²çš„å›è°ƒå‡½æ•°
        Parameters:
        gr_states: dict, å…¨å±€çŠ¶æ€
        Returns:
        history: list, æ¸…ç©ºçš„èŠå¤©è®°å½•
        gr_states: dict, æ›´æ–°åçš„å…¨å±€çŠ¶æ€
        role_info_display: str, æ›´æ–°åçš„è§’è‰²ä¿¡æ¯æ˜¾ç¤º
        audio: None, æ¸…ç©ºéŸ³é¢‘è¾“å‡º
        """
        # è·å–é»˜è®¤è§’è‰²ä¿¡æ¯
        role_name, role_description, system_prompt = init_default_role()
        
        # æ›´æ–°å…¨å±€çŠ¶æ€
        gr_states = {"system_prompt": system_prompt, "history": []}
        
        # æ›´æ–°è§’è‰²ä¿¡æ¯æ˜¾ç¤º
        role_info_display = f''' # {role_name}
        {role_description}
        '''
        
        # æ¸…ç©ºèŠå¤©è®°å½•
        history = []
        
        # æ¸…ç©ºéŸ³é¢‘è¾“å‡º
        audio = None
        
        return history, gr_states, role_info_display, audio

    # åœ¨ gr.Blocks ä¸­å…³è”æŒ‰é’®å’Œå›è°ƒå‡½æ•°
    default_role_btn.click(
        reset_to_default_role,  # å›è°ƒå‡½æ•°
        inputs=[gr_states],  # è¾“å…¥
        outputs=[chatbot, gr_states, role_info_display, audio]  # è¾“å‡º
    )

    def update_model_path(selected_model_name):
        global model_path
        model_path = get_model_path(selected_model_name)
        return model_path
    model.change(
        update_model_path, 
        inputs=[model], 
        outputs=gr.State()  # ä½¿ç”¨çŠ¶æ€å˜é‡æ¥å­˜å‚¨æ¨¡å‹è·¯å¾„
    )

demo.launch(server_port=9877, share=True)
